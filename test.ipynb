{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-13T03:48:51.732502800Z",
     "start_time": "2023-07-13T03:48:42.131809900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17985\n",
      "17985\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "events_data = pd.read_csv('static/First_contest//event_data_train.csv')\n",
    "submissions_data = pd.read_csv('C:/Users/filip/ML/static/First_contest/submissions_data_train.csv')\n",
    "events_data['date'] = pd.to_datetime(events_data.timestamp, unit='s')\n",
    "events_data['day'] = events_data.date.dt.date\n",
    "\n",
    "submissions_data['date'] = pd.to_datetime(submissions_data.timestamp, unit='s')\n",
    "submissions_data['day'] = submissions_data.date.dt.date\n",
    "\n",
    "users_data = events_data.groupby('user_id', as_index=False) \\\n",
    "    .agg({'timestamp': 'max'}) \\\n",
    "    .rename({'timestamp': 'last_timestamp'}, axis='columns')\n",
    "now = 1526772811\n",
    "drop_out_threasold = 2592000\n",
    "\n",
    "users_data['is_gone_user'] = (now - users_data.last_timestamp) > drop_out_threasold\n",
    "users_scores = submissions_data.pivot_table(index='user_id', \\\n",
    "                                            columns='submission_status', \\\n",
    "                                            values='step_id', \\\n",
    "                                            aggfunc='count', \\\n",
    "                                            fill_value=0) \\\n",
    "    .reset_index()\n",
    "users_data = users_data.merge(users_scores, on='user_id', how='outer')\n",
    "users_data = users_data.fillna(0)\n",
    "users_invent_data = events_data.pivot_table(index='user_id',\n",
    "                                            columns='action',\n",
    "                                            values='step_id',\n",
    "                                            aggfunc='count',\n",
    "                                            fill_value=0).reset_index()\n",
    "users_data = users_data.merge(users_invent_data, how='outer')\n",
    "users_days = events_data.groupby('user_id').day.nunique()\n",
    "users_days.to_frame().reset_index()\n",
    "users_data = users_data.merge(users_days, on='user_id', how='outer')\n",
    "users_data['passed_corse'] = users_data.passed > 170\n",
    "\n",
    "submissions_data.step_id.mode()\n",
    "\n",
    "submissions_data\n",
    "\n",
    "events_data\n",
    "\n",
    "submissions_data[submissions_data.submission_status == 'wrong'] \\\n",
    "    .groupby(\"step_id\").agg({'submission_status': 'count'}). \\\n",
    "    sort_values('submission_status', ascending=True).head(10)\n",
    "\n",
    "user_min_time = events_data.groupby('user_id', as_index=False). \\\n",
    "    agg({'timestamp': 'min'}) \\\n",
    "    .rename({\"timestamp\": 'min_timestamp'}, axis=1)\n",
    "users_data = users_data.merge(user_min_time, how='outer')\n",
    "users_data\n",
    "\n",
    "events_data\n",
    "\n",
    "event_data_train = pd.DataFrame()\n",
    "\n",
    "events_data['user_time'] = events_data.user_id.map(str) \\\n",
    "                           + \"_\" + events_data.timestamp.map(str)\n",
    "\n",
    "events_data\n",
    "\n",
    "learning_time_threshold = 3 * 24 * 60 * 60\n",
    "\n",
    "user_learning_time_threshold = user_min_time.user_id.map(str) \\\n",
    "                               + '_' + (learning_time_threshold + user_min_time.min_timestamp).map(str)\n",
    "\n",
    "user_min_time[\"user_learning_time_threshold\"] = user_learning_time_threshold\n",
    "user_min_time\n",
    "\n",
    "events_data = events_data \\\n",
    "    .merge(user_min_time[['user_id', 'user_learning_time_threshold']],\n",
    "           how='outer')\n",
    "\n",
    "events_data.shape\n",
    "\n",
    "events_data_train = events_data[events_data.user_time <= events_data.user_learning_time_threshold]\n",
    "\n",
    "events_data_train.groupby('user_id').day.nunique().max()\n",
    "\n",
    "submissions_data['users_time'] = submissions_data.user_id.map(str) + '_' + submissions_data.timestamp.map(str)\n",
    "submissions_data = submissions_data.merge(user_min_time[['user_id', 'user_learning_time_threshold']], how='outer')\n",
    "submissions_data_train = submissions_data[submissions_data.users_time <= submissions_data.user_learning_time_threshold]\n",
    "submissions_data_train.groupby('user_id').day.nunique().max()\n",
    "\n",
    "X = submissions_data_train.groupby('user_id').day \\\n",
    "    .nunique().to_frame().reset_index().rename(columns={'day': 'days'})\n",
    "\n",
    "steps_tried = submissions_data_train.groupby('user_id').step_id.nunique() \\\n",
    "    .to_frame().reset_index().rename(columns={'step_id': 'steps_tried'})\n",
    "\n",
    "X = X.merge(steps_tried, on='user_id', how='outer')\n",
    "\n",
    "X = X.merge(submissions_data_train.pivot_table(index='user_id', \\\n",
    "                                               columns='submission_status', \\\n",
    "                                               values='step_id', \\\n",
    "                                               aggfunc='count', \\\n",
    "                                               fill_value=0) \\\n",
    "            .reset_index())\n",
    "\n",
    "X['correct_ratio'] = X.correct / (X.correct + X.wrong)\n",
    "\n",
    "X\n",
    "\n",
    "X = X.merge(events_data_train.pivot_table(index='user_id',\n",
    "                                          columns='action', \\\n",
    "                                          values='step_id', \\\n",
    "                                          aggfunc='count', \\\n",
    "                                          fill_value=0) \\\n",
    "            .reset_index()[['user_id', 'viewed']], how='outer')\n",
    "\n",
    "X = X.fillna(0)\n",
    "users_data\n",
    "\n",
    "X = X.merge(users_data[['user_id', 'passed_corse', 'is_gone_user']], how='outer')\n",
    "\n",
    "X\n",
    "\n",
    "X = X[~((X.is_gone_user == False) & (X.passed_corse == False))]\n",
    "\n",
    "X.groupby(['passed_corse', 'is_gone_user']).user_id.count()\n",
    "\n",
    "y = X.passed_corse.map(int)\n",
    "\n",
    "X = X.drop(['passed_corse', 'is_gone_user'], axis=1)\n",
    "\n",
    "X = X.set_index(X.user_id)\n",
    "X = X.drop('user_id', axis=1)\n",
    "\n",
    "# import pandas as pd\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "#\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# dt = DecisionTreeClassifier(criterion='entropy')\n",
    "# parameters = {'max_depth': range(3, 6), 'max_leaf_nodes': range(6, 15), 'min_samples_leaf': range(1, 4),\n",
    "#               'min_samples_split': range(2, 5)}\n",
    "# grid_search_cv_clf = GridSearchCV(dt, parameters, cv=4)\n",
    "# grid_search_cv_clf.fit(X_train, y_train)\n",
    "# model = grid_search_cv_clf.best_estimator_\n",
    "# print(grid_search_cv_clf.best_params_, cross_val_score(model, X_train, y_train, cv=4).mean())\n",
    "#\n",
    "# import pandas as pd\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "#\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# knn = KNeighborsClassifier()\n",
    "# parameters = {'n_neighbors': range(15, 25), 'leaf_size': range(1, 7)}\n",
    "# grid_search_cv_clf = GridSearchCV(knn, parameters, cv=4, n_jobs=-1)\n",
    "# grid_search_cv_clf.fit(X_train, y_train)\n",
    "# model = grid_search_cv_clf.best_estimator_\n",
    "# print(grid_search_cv_clf.best_params_, cross_val_score(model, X_train, y_train, cv=4).mean())\n",
    "#\n",
    "# from sklearn.linear_model import LogisticRegressionCV\n",
    "# from sklearn.model_selection import train_test_split\n",
    "#\n",
    "# clf = LogisticRegressionCV(cv=5)\n",
    "#\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=41)\n",
    "#\n",
    "# clf.fit(X_train, y_train)\n",
    "# print(clf.score(X_test, y_test))\n",
    "# print(clf.coef_)\n",
    "# print(clf.intercept_)\n",
    "# print(cross_val_score(clf, X_train, y_train, cv=4).mean())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
